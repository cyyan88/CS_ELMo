# -*- coding: utf-8 -*-
"""390project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lI8_hseJrBBXbmuSpGzXbeZZzUG_X9LA
"""

import tensorflow as tf
import tensorflow_hub as hub
from keras.layers import Input, LSTM, Dense, TimeDistributed, Bidirectional, Concatenate, Embedding
from keras.models import Model
#from keras_contrib.layers import CRF

def load_conll_dataset(file_path):
    sentences = []
    with open(file_path, 'r', encoding='utf-8') as f:
        sentence = []
        for line in f:
            line = line.strip()
          #  print(line)
            if line.startswith("# sent_enum"):
                continue
            if line == '':
                if len(sentence) > 0:
                    sentences.append(sentence)
                    sentence = []
                continue
            parts = line.split('\t')
            if len(parts) < 3: continue
            word = parts[0]
            lang_tag = parts[1]
            pos_tag = parts[2]
            sentence.append((word, lang_tag, pos_tag))
    return sentences

# Example usage
file_path = 'your_conll_dataset.conll'
dataset = load_conll_dataset("/content/train.conll")
print(len(dataset))
print(dataset[0:10])

# https://paperswithcode.com/paper/from-english-to-code-switching-transfer
# next steps: convert dataset into format of .txt files ^^

import random
data = dataset
# Shuffle the data randomly
random.seed(42)  # Setting seed for reproducibility
random.shuffle(data)

# Define the proportions for dev, train, and test sets
dev_ratio = 0.001
train_ratio = 0.001
test_ratio = 0.001

# Calculate the number of samples for each set
num_samples = len(data)
num_dev = int(num_samples * dev_ratio)
num_train = int(num_samples * train_ratio)
num_test = int(num_samples * test_ratio)
print(num_dev, num_train, num_test)

# Split the data into dev, train, and test sets
dev_set = data[:num_dev]
train_set = data[num_dev:num_dev + num_train]
test_set = data[num_dev + num_train:num_dev + num_train+num_test]

# Function to convert data to the required format
def convert_to_txt(data):
    output = ""
    for sentence in data:
        for word_info in sentence:
            word, lang, tag = word_info
            output += f"{word}\t{lang}\t{tag}\n"
        output += "\n"
    return output

# Convert data to text for each set
dev_text = convert_to_txt(dev_set)
train_text = convert_to_txt(train_set)
test_text = convert_to_txt(test_set)

# Save the text to files for dev, train, and test
with open("dev.txt", "w") as file:
    file.write(dev_text)

with open("train.txt", "w") as file:
    file.write(train_text)

with open("test.txt", "w") as file:
    file.write(test_text)

